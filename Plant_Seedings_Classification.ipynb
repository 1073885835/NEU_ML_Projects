{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61940,"databundleVersionId":6964249,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport random\nimport joblib\nfrom collections import Counter\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom skimage import feature as ft\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, StackingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:07:27.337588Z","iopub.execute_input":"2023-11-17T06:07:27.337821Z","iopub.status.idle":"2023-11-17T06:07:32.468398Z","shell.execute_reply.started":"2023-11-17T06:07:27.337798Z","shell.execute_reply":"2023-11-17T06:07:32.466741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"/kaggle/input/neu-plantseedlingsclassification12/Nonsegmented_pack - k/\"\n\nclass_names = os.listdir(data_dir + \"train/\")\nclasses_dict = dict()\n\nfor i, name in enumerate(class_names):\n    classes_dict[name] = i\nclasses_dict","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:07:56.067535Z","iopub.execute_input":"2023-11-17T06:07:56.067930Z","iopub.status.idle":"2023-11-17T06:07:56.084945Z","shell.execute_reply.started":"2023-11-17T06:07:56.067896Z","shell.execute_reply":"2023-11-17T06:07:56.083555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 直方图均衡化\ndef equalize(img):\n    \"\"\"Parameter `img` is read by cv2.imread(), so it is in BGR mode\"\"\"\n    \n    b, g, r = cv2.split(img)\n    \n    b = cv2.equalizeHist(b)\n    g = cv2.equalizeHist(g)    \n    r = cv2.equalizeHist(r)\n    \n    img_equalized = cv2.merge((b, g, r))\n    \n    return img_equalized","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:07:59.841586Z","iopub.execute_input":"2023-11-17T06:07:59.842010Z","iopub.status.idle":"2023-11-17T06:07:59.848652Z","shell.execute_reply.started":"2023-11-17T06:07:59.841977Z","shell.execute_reply":"2023-11-17T06:07:59.847376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#测试效果\nimg_bgr_try = cv2.imread(data_dir + \"train/Charlock/aahijusizs.png\")\nimg_equalized = equalize(img_bgr_try)\n\nfig  = plt.figure(figsize=(8, 16))\nax1 = plt.subplot(121)\nax1.imshow(img_bgr_try)\nax1.set_title(\"Original Image (BGR)\")\nax2 = plt.subplot(122)\nax2.imshow(img_equalized)\nax2.set_title(\"Applying Histogram Equalization (BGR)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:08:02.754806Z","iopub.execute_input":"2023-11-17T06:08:02.755226Z","iopub.status.idle":"2023-11-17T06:08:03.322905Z","shell.execute_reply.started":"2023-11-17T06:08:02.755190Z","shell.execute_reply":"2023-11-17T06:08:03.321589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#只要绿色的部分\ndef extract_seedling(img):\n    \"\"\"Parameter `img` is read by cv2.imread(), so it is in BGR mode\"\"\"\n    \n    # Green color range\n    green_lower = np.array([35, 43, 46], dtype=\"uint8\")   # Lower bound\n    green_upper = np.array([90, 255, 255], dtype=\"uint8\") # Upper bound\n    \n    # Gaussian filtering\n    img_gaussed = cv2.GaussianBlur(img, (3, 3), 0)\n    img_gaussed = cv2.cvtColor(img_gaussed, cv2.COLOR_BGR2HSV)\n    \n    # Binarization to create mask\n    mask = cv2.inRange(img_gaussed, green_lower, green_upper)\n    \n    img_extracted = cv2.bitwise_and(img, img, mask=mask)\n    \n    return img_extracted","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:08:07.267988Z","iopub.execute_input":"2023-11-17T06:08:07.268368Z","iopub.status.idle":"2023-11-17T06:08:07.274989Z","shell.execute_reply.started":"2023-11-17T06:08:07.268326Z","shell.execute_reply":"2023-11-17T06:08:07.273942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#测试\n\nimg_bgr_try = cv2.imread(data_dir + \"train/Charlock/aahijusizs.png\")\nimg_extracted = extract_seedling(img_bgr_try)\n\nfig  = plt.figure(figsize=(8, 16))\nax1 = plt.subplot(121)\nax1.imshow(img_bgr_try)\nax1.set_title(\"Original Image (BGR)\")\nax2 = plt.subplot(122)\nax2.imshow(img_extracted)\nax2.set_title(\"Extracting Seedling Parts (BGR)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:08:10.572157Z","iopub.execute_input":"2023-11-17T06:08:10.572629Z","iopub.status.idle":"2023-11-17T06:08:11.000268Z","shell.execute_reply.started":"2023-11-17T06:08:10.572593Z","shell.execute_reply":"2023-11-17T06:08:10.999053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing_imgs(file_dir):\n    \"\"\"Preprocess train image by applying equalize() and then extract_seedling().\n       Store the preprocessed images in train_preprocessed folder and get their class labels.\"\"\"\n    \n    images_list = []\n    labels_list = []\n    \n    classes = os.listdir(file_dir)\n    # print(classes)\n    \n    for cls in classes:\n        img_names = os.listdir(file_dir + cls)\n        # cls_folder = train_preprocessed_dir + cls\n        # if not os.path.exists(cls_folder):\n        #     os.makedirs(cls_folder)        # Create class folder if it does not exist\n            \n        for img_name in img_names:\n            img_bgr = cv2.imread(file_dir + cls + '/' + img_name)\n            img_equalized = equalize(img_bgr)\n            img_seedling = extract_seedling(img_equalized)\n            # cv2.imwrite(cls_folder + '/' + img_name, img_seedling)\n            \n            images_list.append(img_seedling)\n            labels_list.append(classes_dict[cls])\n\n    return images_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:08:15.251874Z","iopub.execute_input":"2023-11-17T06:08:15.252264Z","iopub.status.idle":"2023-11-17T06:08:15.260332Z","shell.execute_reply.started":"2023-11-17T06:08:15.252234Z","shell.execute_reply":"2023-11-17T06:08:15.258742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_list, labels_list = preprocessing_imgs(data_dir + \"train/\")\nnum_per_class = Counter(labels_list)\nnum_per_class","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:08:19.214805Z","iopub.execute_input":"2023-11-17T06:08:19.215214Z","iopub.status.idle":"2023-11-17T06:09:39.826967Z","shell.execute_reply.started":"2023-11-17T06:08:19.215178Z","shell.execute_reply":"2023-11-17T06:09:39.825571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_label = np.array(labels_list)\n\nprint(f'图像数量: {len(images_list)}')                 # 4440\nprint(f'第一张图片的shape: {images_list[0].shape}')    # (w, h, 3)\nprint(f'label数量: {all_label.shape[0]}')              # 4440","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:01.126111Z","iopub.execute_input":"2023-11-17T06:10:01.126539Z","iopub.status.idle":"2023-11-17T06:10:01.134571Z","shell.execute_reply.started":"2023-11-17T06:10:01.126507Z","shell.execute_reply":"2023-11-17T06:10:01.132921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_imgs(images_list):\n    \"\"\"Resize images into the shape as (256, 256, 3) to ensure that they have the same shape.\"\"\"\n    \n    imgs_list = []\n    for image in images_list:\n        image = cv2.resize(image, (128, 128)) \n        imgs_list.append(image)\n    return imgs_list","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:04.193915Z","iopub.execute_input":"2023-11-17T06:10:04.194314Z","iopub.status.idle":"2023-11-17T06:10:04.201733Z","shell.execute_reply.started":"2023-11-17T06:10:04.194285Z","shell.execute_reply":"2023-11-17T06:10:04.199570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 填充缺失值\ndef fill_missing(feature):\n    feature_df = pd.DataFrame(feature)      # 转为 DataFrame 格式，才能使用 fillna 函数\n    feature_df_fill = feature_df.fillna(0)  # 将缺失值部分填充0\n    \n    return np.array(feature_df_fill)        # 返回array格式","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:07.406478Z","iopub.execute_input":"2023-11-17T06:10:07.406864Z","iopub.status.idle":"2023-11-17T06:10:07.414217Z","shell.execute_reply.started":"2023-11-17T06:10:07.406836Z","shell.execute_reply":"2023-11-17T06:10:07.412680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 标准化\ndef normalize(feature):\n    scaler = StandardScaler()\n    scaler.fit(feature)\n    feature_normal = scaler.transform(feature)\n    \n    return feature_normal","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:10.188873Z","iopub.execute_input":"2023-11-17T06:10:10.189529Z","iopub.status.idle":"2023-11-17T06:10:10.195020Z","shell.execute_reply.started":"2023-11-17T06:10:10.189486Z","shell.execute_reply":"2023-11-17T06:10:10.193940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use PCA(Principal Component Analysis) to reduce dimensionality\ndef dimensionalityReduction(feature, n=100, is_whiten=False, is_show=True):\n    estimator = PCA(n_components=n, whiten=is_whiten)\n    pca_feature = estimator.fit_transform(feature)\n    \n    sum = 0\n    for ratio in estimator.explained_variance_ratio_:\n        sum += ratio\n        if is_show:\n            print(sum)\n    \n    print('降维后特征矩阵shape为:', pca_feature.shape)\n    print('主成分比例为:', sum)\n    \n    return pca_feature","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:13.313476Z","iopub.execute_input":"2023-11-17T06:10:13.313845Z","iopub.status.idle":"2023-11-17T06:10:13.320692Z","shell.execute_reply.started":"2023-11-17T06:10:13.313815Z","shell.execute_reply":"2023-11-17T06:10:13.319592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.getcwd())\n\nos.makedirs(\"./save_features\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:18.304715Z","iopub.execute_input":"2023-11-17T06:10:18.305117Z","iopub.status.idle":"2023-11-17T06:10:18.311941Z","shell.execute_reply.started":"2023-11-17T06:10:18.305083Z","shell.execute_reply":"2023-11-17T06:10:18.310331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_dir = \"./save_features/\"\n\n# 将提取出的特征数组（二维）保存到npy文件中\ndef save_feature(feature, fileName):\n    np.save(feature_dir + fileName + '.npy', feature, allow_pickle=True)\n    \n    print(fileName + '.npy', '文件已生成！')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:21.590448Z","iopub.execute_input":"2023-11-17T06:10:21.590836Z","iopub.status.idle":"2023-11-17T06:10:21.597811Z","shell.execute_reply.started":"2023-11-17T06:10:21.590806Z","shell.execute_reply":"2023-11-17T06:10:21.595994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_dir = \"./save_features/\"\n\n# 读取之前保存好的 feature 文件，返回特征矩阵（二维数组）\ndef read_feature(fileName):\n    feature = np.load(feature_dir + fileName + '.npy', allow_pickle=True)\n    print('已读取', fileName, '文件！\\t shape = ', feature.shape)\n\n    return feature","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:24.922524Z","iopub.execute_input":"2023-11-17T06:10:24.922880Z","iopub.status.idle":"2023-11-17T06:10:24.929271Z","shell.execute_reply.started":"2023-11-17T06:10:24.922851Z","shell.execute_reply":"2023-11-17T06:10:24.927664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SIFT特征\ndef sift_feature(images_list):\n    \"\"\"Extract SIFT feature of the image\"\"\"\n    \n    feature_sift_list = []  # SIFT特征向量列表\n    fail_count=0\n    # sift = cv2.xfeatures2d.SIFT_create()   # old-version cv2\n    sift = cv2.SIFT_create()\n    \n    for i in tqdm(range(len(images_list))):\n        image = cv2.cvtColor(images_list[i], cv2.COLOR_BGR2GRAY)\n        \n        # Obtain SIFT feature，kp is keypoints，des is descriptors (feature vectors)\n        kp, des = sift.detectAndCompute(image, None)\n        if des is None:\n            fail_count += 1\n            des = feature_sift_list[len(feature_sift_list) - 1]\n        feature_sift_list.append(des)\n        \n    return feature_sift_list","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:28.198712Z","iopub.execute_input":"2023-11-17T06:10:28.199098Z","iopub.status.idle":"2023-11-17T06:10:28.207322Z","shell.execute_reply.started":"2023-11-17T06:10:28.199067Z","shell.execute_reply":"2023-11-17T06:10:28.205445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n## TEST SIFT\nsift = cv2.SIFT_create()\n\nimg_extracted_gray = cv2.cvtColor(img_extracted, cv2.COLOR_BGR2GRAY)\n\nkp = sift.detect(img_extracted_gray, None)   #  找到关键点\n\n# 绘制关键点 \nimg_kp_gray = cv2.drawKeypoints(img_extracted_gray, kp, img_extracted_gray)\n\n# 计算关键点对应的sift特征向量\n# kp为关键点列表，des为numpy的数组，为 (关键点数目,128)\nkp, des = sift.compute(img_kp_gray, kp)\n\nprint('kp[0] =', kp[0])\nprint('len(kp) =', len(kp))\nprint('des.shape =', des.shape)\n\nplt.figure(figsize=(8,8))\nplt.imshow(img_kp_gray)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:31.490147Z","iopub.execute_input":"2023-11-17T06:10:31.490589Z","iopub.status.idle":"2023-11-17T06:10:31.626522Z","shell.execute_reply.started":"2023-11-17T06:10:31.490551Z","shell.execute_reply":"2023-11-17T06:10:31.625131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# 获取 SIFT 特征列表\nfeature_sift_list = sift_feature(images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:10:39.432186Z","iopub.execute_input":"2023-11-17T06:10:39.432554Z","iopub.status.idle":"2023-11-17T06:13:14.959111Z","shell.execute_reply.started":"2023-11-17T06:10:39.432528Z","shell.execute_reply":"2023-11-17T06:13:14.957510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(feature_sift_list))     # 4440\nprint(feature_sift_list[0])\nprint()\n\n# 以下3个输出为sift特征的 shape, 为 (关键点数量, 128)\nprint(feature_sift_list[0].shape)      # (?, 128)\nprint(feature_sift_list[1].shape)      # (?, 128)\nprint(feature_sift_list[100].shape)    # (?, 128)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:13:48.486108Z","iopub.execute_input":"2023-11-17T06:13:48.486477Z","iopub.status.idle":"2023-11-17T06:13:48.494495Z","shell.execute_reply.started":"2023-11-17T06:13:48.486446Z","shell.execute_reply":"2023-11-17T06:13:48.492766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 初始化BOW提取器\n\ndef bow_init(feature_sift_list):\n    \"\"\"Initialize BOW trainer\"\"\"\n    \n    ## 创建BOW训练器，指定 k-means 参数 k 把处理好的特征数据全部合并，利用聚类把特征词分为若干类，\n    ## 此若干类的数目由自己设定，每一类相当于一个视觉词汇\n    bow_kmeans_trainer = cv2.BOWKMeansTrainer(100)    # 100 个词汇\n    \n    for feature_sift in feature_sift_list:\n        bow_kmeans_trainer.add(feature_sift)\n    \n    # 进行k-means聚类，返回词汇字典 也就是聚类中心\n    voc = bow_kmeans_trainer.cluster()\n    \n    # 输出词汇字典\n    print(\"In bow_init(), print variable `voc`: \")\n    print(type(voc), voc.shape)    # <class 'numpy.ndarray'> (100, 256)\n    print(voc)\n    print()\n    \n    # FLANN 匹配  \n    # algorithm 用来指定匹配所使用的算法，可以选择的有 LinearIndex、KTreeIndex、KMeansIndex、CompositeIndex 和 AutotuneIndex\n    # 这里选择的是 KTreeIndex (使用 kd树 实现最近邻搜索)\n    flann_params = dict(algorithm=1, tree=5)           # define parameters for cv2.FlannBasedMatcher()\n    flann = cv2.FlannBasedMatcher(flann_params,{})\n    \n    print(flann)\n    \n    #初始化 bow 提取器(设置词汇字典),用于提取每一张图像的BOW特征描述\n    # sift = cv2.xfeatures2d.SIFT_create()   # old-version cv2\n    sift = cv2.SIFT_create()\n    bow_img_descriptor_extractor = cv2.BOWImgDescriptorExtractor(sift, flann)        \n    bow_img_descriptor_extractor.setVocabulary(voc)\n    \n    print(bow_img_descriptor_extractor)\n    \n    return bow_img_descriptor_extractor","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:13:51.838137Z","iopub.execute_input":"2023-11-17T06:13:51.838519Z","iopub.status.idle":"2023-11-17T06:13:51.847594Z","shell.execute_reply.started":"2023-11-17T06:13:51.838491Z","shell.execute_reply":"2023-11-17T06:13:51.846139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## BOW特征\ndef bow_feature(bow_img_descriptor_extractor, images_list):\n    # 分别对每个图片提取BOW特征，获得BOW特征列表\n    feature_bow_list = []\n    \n    # sift = cv2.xfeatures2d.SIFT_create()   # old-version cv2\n    sift = cv2.SIFT_create()\n    for i in tqdm(range(len(images_list))):\n        image = cv2.cvtColor(images_list[i], cv2.COLOR_BGR2GRAY)\n        feature_bow = bow_img_descriptor_extractor.compute(image,sift.detect(image))\n        feature_bow_list.append(feature_bow)\n        \n    return np.array(feature_bow_list)[:,0,:]","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:13:55.511296Z","iopub.execute_input":"2023-11-17T06:13:55.511659Z","iopub.status.idle":"2023-11-17T06:13:55.520140Z","shell.execute_reply.started":"2023-11-17T06:13:55.511635Z","shell.execute_reply":"2023-11-17T06:13:55.518151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n## 获取 SIFT + BOW 特征\n\n# 从图像中提取并保存在npy文件中\nbow_extractor = bow_init(feature_sift_list)\nall_feature_bow = bow_feature(bow_extractor, images_list)  # shape = (4440, 100)\n# save_feature(all_feature_bow, 'all_feature_bow')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:13:58.522311Z","iopub.execute_input":"2023-11-17T06:13:58.522725Z","iopub.status.idle":"2023-11-17T06:25:27.650571Z","shell.execute_reply.started":"2023-11-17T06:13:58.522690Z","shell.execute_reply":"2023-11-17T06:25:27.648785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 所有图片 resize 成(256,256)，保证每个图像提取出的 HOG，LBP 特征数量一致\n# 提取 HOG，LBP 特征前调用\nimages_list = resize_imgs(images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:25:51.184324Z","iopub.execute_input":"2023-11-17T06:25:51.184762Z","iopub.status.idle":"2023-11-17T06:25:51.630827Z","shell.execute_reply.started":"2023-11-17T06:25:51.184733Z","shell.execute_reply":"2023-11-17T06:25:51.628819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import color, feature\nfrom tqdm import tqdm\n\n# 提取 HOG 特征\ndef hog_feature(image_list):\n    feature_hog_list = []\n    for i in tqdm(range(len(image_list))):  # ft is short for skimage.feature\n        gray = cv2.cvtColor(image_list[i], cv2.COLOR_RGB2GRAY)\n        feature_hog = ft.hog(gray, \n                             orientations=12, \n                             pixels_per_cell=(16, 16), \n                             cells_per_block=(3, 3))\n        feature_hog_list.append(feature_hog)\n    \n    return np.array(feature_hog_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:25:55.580741Z","iopub.execute_input":"2023-11-17T06:25:55.581112Z","iopub.status.idle":"2023-11-17T06:25:55.589758Z","shell.execute_reply.started":"2023-11-17T06:25:55.581084Z","shell.execute_reply":"2023-11-17T06:25:55.588420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n## 获取 HOG 特征\n## 从图像中提取并保存在 csv 文件中\nall_feature_hog = hog_feature(images_list)\n\n# print('all_feature_hog.shape =', all_feature_hog.shape)\n# save_feature(all_feature_hog, 'all_feature_hog')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:26:04.069614Z","iopub.execute_input":"2023-11-17T06:26:04.070032Z","iopub.status.idle":"2023-11-17T06:26:12.164912Z","shell.execute_reply.started":"2023-11-17T06:26:04.070000Z","shell.execute_reply":"2023-11-17T06:26:12.163384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.feature import hog\nfrom skimage import color\n\n# 将多通道图像转换为灰度图像\ngray_img = color.rgb2gray(img_extracted)\n\n# 对灰度图像应用HOG特征提取\nfeature_hog = hog(gray_img,\n                  orientations=16,\n                  pixels_per_cell=(32, 32),\n                  cells_per_block=(3, 3),\n                  feature_vector=True,\n                  visualize=True)\n\nprint(feature_hog[0].shape[0])\nplt.imshow(feature_hog[1], cmap=plt.cm.gray)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:26:18.018746Z","iopub.execute_input":"2023-11-17T06:26:18.019093Z","iopub.status.idle":"2023-11-17T06:26:18.311049Z","shell.execute_reply.started":"2023-11-17T06:26:18.019064Z","shell.execute_reply":"2023-11-17T06:26:18.310066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 提取LBP特征\ndef lbp_feature(image_list):\n    feature_lbp_list = []\n    for j in tqdm(range(len(image_list))):\n        feature_lbp = []\n        image = image_list[j]\n        for i in range(3):\n            feature_lbp.append(ft.local_binary_pattern(np.array(image[:,:,i]), 64, 64, 'var'))\n        feature_lbp_list.append(feature_lbp)\n    return np.array(feature_lbp_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:26:23.246163Z","iopub.execute_input":"2023-11-17T06:26:23.246578Z","iopub.status.idle":"2023-11-17T06:26:23.255937Z","shell.execute_reply.started":"2023-11-17T06:26:23.246542Z","shell.execute_reply":"2023-11-17T06:26:23.253378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n## 获取 LBP 特征\nall_feature_lbp = lbp_feature(images_list)    # shape = (4440, 3, 256, 256)\nprint(np.array(all_feature_lbp).shape)        # (4440, 3, 256, 256)\n\n\n\n## 将四维转为二维\nall_feature_lbp = all_feature_lbp.reshape(all_feature_lbp.shape[0], \n                                          all_feature_lbp.shape[1] * all_feature_lbp.shape[2] * all_feature_lbp.shape[3])\n\nprint('all_feature_lbp.shape =', all_feature_lbp.shape)  # (4440, 196608)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:26:30.039605Z","iopub.execute_input":"2023-11-17T06:26:30.040026Z","iopub.status.idle":"2023-11-17T06:29:15.404130Z","shell.execute_reply.started":"2023-11-17T06:26:30.039993Z","shell.execute_reply":"2023-11-17T06:29:15.402856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST LBP\nfeature_lbp = []\nfor i in range(3):\n    feature_lbp.append(ft.local_binary_pattern(img_extracted[:,:,i], 64, 64, 'var'))\nprint(feature_lbp)    # list of ndarray\nprint()\n\nfeature_lbp_array = np.array(feature_lbp)\nprint(feature_lbp_array.shape)\n\n# 挑选出非 nan 值\nfeature_lbp_array[np.logical_not(np.isnan(feature_lbp_array))]","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:29:22.473309Z","iopub.execute_input":"2023-11-17T06:29:22.473693Z","iopub.status.idle":"2023-11-17T06:29:22.553630Z","shell.execute_reply.started":"2023-11-17T06:29:22.473664Z","shell.execute_reply":"2023-11-17T06:29:22.552321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 填充缺失值\nall_feature_lbp = fill_missing(all_feature_lbp)  \n# save_feature(all_feature_lbp, 'all_feature_lbp')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:29:26.964808Z","iopub.execute_input":"2023-11-17T06:29:26.965305Z","iopub.status.idle":"2023-11-17T06:29:28.036760Z","shell.execute_reply.started":"2023-11-17T06:29:26.965269Z","shell.execute_reply":"2023-11-17T06:29:28.034936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nall_feature_bow_normal = normalize(all_feature_bow)\nsave_feature(all_feature_bow_normal, 'all_feature_bow_normal')\n\nall_feature_hog_normal = normalize(all_feature_hog)\nsave_feature(all_feature_hog_normal, 'all_feature_hog_normal')\n\nall_feature_lbp_normal = normalize(all_feature_lbp)\nsave_feature(all_feature_lbp_normal, 'all_feature_lbp_normal')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:29:31.536755Z","iopub.execute_input":"2023-11-17T06:29:31.537995Z","iopub.status.idle":"2023-11-17T06:29:34.517311Z","shell.execute_reply.started":"2023-11-17T06:29:31.537951Z","shell.execute_reply":"2023-11-17T06:29:34.515653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nprint('all_feature_bow.shape =', all_feature_bow.shape)    # all_feature_hog.shape = (4440, 100)\npca_feature_bow = dimensionalityReduction(all_feature_bow, 100)\nprint('pca_feature_bow.shape =', pca_feature_bow.shape)    # pca_feature_hog.shape = (4440, 100)\nsave_feature(pca_feature_bow, 'pca_feature_bow')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:29:40.537815Z","iopub.execute_input":"2023-11-17T06:29:40.538152Z","iopub.status.idle":"2023-11-17T06:29:40.580529Z","shell.execute_reply.started":"2023-11-17T06:29:40.538129Z","shell.execute_reply":"2023-11-17T06:29:40.579591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nprint('all_feature_hog.shape =', all_feature_hog.shape)    # all_feature_hog.shape = (4440, 21168)\npca_feature_hog = dimensionalityReduction(all_feature_hog, 1000)\nprint('pca_feature_hog.shape =', pca_feature_hog.shape)    # pca_feature_hog.shape = (4440, 4000)\nsave_feature(pca_feature_hog, 'pca_feature_hog')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:30:12.870078Z","iopub.execute_input":"2023-11-17T06:30:12.870515Z","iopub.status.idle":"2023-11-17T06:30:20.923228Z","shell.execute_reply.started":"2023-11-17T06:30:12.870486Z","shell.execute_reply":"2023-11-17T06:30:20.921751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nprint('all_feature_lbp.shape =', all_feature_lbp.shape)  # all_feature_lbp.shape = (4440, 196608)\npca_feature_lbp = dimensionalityReduction(all_feature_lbp, 500, True)\nprint('pca_feature_lbp.shape =', pca_feature_lbp.shape)  # pca_feature_lbp.shape = (4440, 100)\nsave_feature(pca_feature_lbp, 'pca_feature_lbp')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:31:15.224010Z","iopub.execute_input":"2023-11-17T06:31:15.224474Z","iopub.status.idle":"2023-11-17T06:31:48.809699Z","shell.execute_reply.started":"2023-11-17T06:31:15.224441Z","shell.execute_reply":"2023-11-17T06:31:48.807556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将 SIFT+BOW, HOG, LBP 三种特征矩阵拼合到一起\n# all_feature_list = [all_feature_bow_normal, pca_feature_hog, pca_feature_lbp]\nall_feature_list = [pca_feature_bow, pca_feature_hog, pca_feature_lbp]\n\nall_feature = [[] for i in range(4440)]  # 创建二维空数组，行数为 4440\n\nfor feature in all_feature_list:\n    all_feature = np.hstack((all_feature, feature))\n    \nprint(all_feature.shape)\n\nnp.save(feature_dir + 'all_feature', all_feature, allow_pickle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:32:01.776154Z","iopub.execute_input":"2023-11-17T06:32:01.777605Z","iopub.status.idle":"2023-11-17T06:32:01.836867Z","shell.execute_reply.started":"2023-11-17T06:32:01.777561Z","shell.execute_reply":"2023-11-17T06:32:01.836016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 按类划分数据集\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\nsss.get_n_splits(all_feature, all_label)\nfor train_index, test_index in sss.split(all_feature, all_label):\n    x_train, x_val = all_feature[train_index], all_feature[test_index]\n    y_train, y_val = all_label[train_index], all_label[test_index]\n\nprint(\"x_train: \", x_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"x_val  : \", x_val.shape)\nprint(\"y_val  : \", y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:32:06.061674Z","iopub.execute_input":"2023-11-17T06:32:06.062083Z","iopub.status.idle":"2023-11-17T06:32:06.086329Z","shell.execute_reply.started":"2023-11-17T06:32:06.062050Z","shell.execute_reply":"2023-11-17T06:32:06.084584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_class_train = np.zeros(12, dtype=np.int64)\nnum_class_val = np.zeros(12, dtype=np.int64)\nfor y in y_train:\n    num_class_train[y] += 1\nfor y in y_val:\n    num_class_val[y] += 1\n    \nprint('划分后训练集中各类的数量 =', num_class_train)\nprint('数据集中各类的数量 * 0.8 =', [round((i * 0.8), 1) for i in num_per_class.values()])\nprint('划分后验证集中各类的数量 =', num_class_val)\nprint('数据集中各类的数量 * 0.2 =', [round((i * 0.2), 1) for i in num_per_class.values()])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:32:09.665065Z","iopub.execute_input":"2023-11-17T06:32:09.665519Z","iopub.status.idle":"2023-11-17T06:32:09.676052Z","shell.execute_reply.started":"2023-11-17T06:32:09.665479Z","shell.execute_reply":"2023-11-17T06:32:09.674768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 展示各类的准确率、召回率、f1-score，及混淆矩阵可视化\ndef category_show(model, x_val, y_val):\n    target_names = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat',\n                    'Fat Hen', 'Loose Silky-bent', 'Maize','Scentless Mayweed', 'Shepherds Purse', \n                    'Small-flowered Cranesbill', 'Sugar beet']\n    y_pred = model.predict(x_val)\n    \n    print(classification_report(y_val, y_pred, target_names=target_names))\n    cm = confusion_matrix(y_val, y_pred)\n    cm_display = ConfusionMatrixDisplay(cm).plot()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:32:19.476747Z","iopub.execute_input":"2023-11-17T06:32:19.477110Z","iopub.status.idle":"2023-11-17T06:32:19.485830Z","shell.execute_reply.started":"2023-11-17T06:32:19.477081Z","shell.execute_reply":"2023-11-17T06:32:19.484168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# XGBoost 模型\nmodel_xgb = XGBClassifier(# objective=\"multi:softmax\",\n                          objective='multi:softproba',\n                          n_estimators=1000,\n                          num_class=12,\n                          learning_rate=0.1,\n                          # tree_method='gpu_hist', \n                          # gpu_id=-1,\n                          max_depth=6, \n                          min_child_weight=2, \n                          max_delta_step=3, \n                          subsample=1, \n                          gamma=0, \n                          n_jobs=-1,)\n\nmodel_xgb.fit(x_train, y_train, \n              early_stopping_rounds=10, \n              eval_set=[(x_val, y_val)], \n              eval_metric='mlogloss', \n              verbose=50)\nscore_xgb = model_xgb.score(x_val, y_val)\nprint('score_xgb =', score_xgb)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:24:20.153964Z","iopub.execute_input":"2023-11-17T07:24:20.154422Z","iopub.status.idle":"2023-11-17T07:48:48.172126Z","shell.execute_reply.started":"2023-11-17T07:24:20.154381Z","shell.execute_reply":"2023-11-17T07:48:48.170059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_xgb, x_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:48:54.410291Z","iopub.execute_input":"2023-11-17T07:48:54.410832Z","iopub.status.idle":"2023-11-17T07:48:55.233108Z","shell.execute_reply.started":"2023-11-17T07:48:54.410795Z","shell.execute_reply":"2023-11-17T07:48:55.230771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# LightGBM 模型\nmodel_lgb = lgb.LGBMClassifier(learning_rate=0.1, \n                               objective='multiclass', \n                               num_class=12, \n                               n_estimators=1500, \n                               max_depth=3, \n                               sub_sample=0.7, \n                               n_jobs=-1)\nmodel_lgb.fit(x_train, y_train, \n              early_stopping_rounds=10, \n              eval_set=[(x_val, y_val)], \n              eval_metric ='logloss', \n              verbose=10)\nscore_lgb = model_lgb.score(x_val, y_val)\nprint('score_lgb =', score_lgb)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:48:31.903812Z","iopub.execute_input":"2023-11-17T06:48:31.904300Z","iopub.status.idle":"2023-11-17T06:49:23.547142Z","shell.execute_reply.started":"2023-11-17T06:48:31.904251Z","shell.execute_reply":"2023-11-17T06:49:23.546413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_lgb, x_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:49:02.192695Z","iopub.execute_input":"2023-11-17T07:49:02.193076Z","iopub.status.idle":"2023-11-17T07:49:02.828487Z","shell.execute_reply.started":"2023-11-17T07:49:02.193049Z","shell.execute_reply":"2023-11-17T07:49:02.827040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# GBDT模型\nmodel_gbdt = GradientBoostingClassifier(learning_rate=0.1, n_estimators=500, max_depth=3)\nmodel_gbdt.fit(x_train, y_train)\nscore_gbdt = model_gbdt.score(x_val, y_val)\nprint('score_gbdt =', score_gbdt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_gbdt, x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# RandomForest 模型\nmodel_rf = RandomForestClassifier(n_estimators=150, n_jobs=-1)\nmodel_rf.fit(x_train, y_train)\nscore_rf = model_rf.score(x_val, y_val)\nprint('score_rf =', score_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_rf, x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# SVC 模型\nmodel_SVC = SVC(C=1)\nmodel_SVC.fit(x_train, y_train)\nscore_SVC = model_SVC.score(x_val, y_val)\nprint('score_SVC =', score_SVC)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_SVC, x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_knn = KNeighborsClassifier(n_neighbors=1)\nmodel_knn.fit(x_train, y_train)\nscore_knn = model_knn.score(x_val, y_val)\nprint('score_knn =', score_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_knn, x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmodel_sgdc = SGDClassifier(max_iter=1000, tol=1e-3)\nmodel_sgdc.fit(x_train, y_train)\nscore_sgdc = model_sgdc.score(x_val, y_val)\nprint('score_sgdc =', score_sgdc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_sgdc, x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ET = ExtraTreesClassifier()\nmodel_ET.fit(x_train, y_train)\nscore_ET = model_ET.score(x_val, y_val)\nprint('score_ET =', score_ET)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_show(model_ET, x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nestimators = [('rf', model_rf),\n              ('lgb', lgb.LGBMClassifier(learning_rate=0.1, \n                                         objective='multiclass', \n                                         num_class=12, \n                                         n_estimators=150, \n                                         max_depth=2, \n                                         n_jobs=-1)),\n              ('SVC', model_SVC),\n              ('SGDC', model_sgdc),\n              ('ET', model_ET)\n             ]\n\nmodel_stack = StackingClassifier(estimators=estimators, \n                                 final_estimator= XGBClassifier(learning_rate=0.1, \n                                                                # objective='multi:softmax',\n                                                                objective='multi:softproba',\n                                                                num_class=12, \n                                                                n_estimators=500, \n                                                                # tree_method='gpu_hist', \n                                                                # gpu_id=0, \n                                                                max_depth=3, \n                                                                min_child_weight=3, \n                                                                max_delta_step=3, \n                                                                subsample=0.7, \n                                                                gamma=0, \n                                                                n_jobs=-1, \n                                                                use_label_encoder=False)\n                                )\n\nmodel_stack.fit(x_train, y_train)\n\nscore_stack = model_stack.score(x_val, y_val)\nprint('score_stack =', score_stack)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing_test_imgs(file_dir):\n    \"\"\"Preprocess train image by applying equalize() and then extract_seedling().\n       Store the preprocessed images in train_preprocessed folder and get their class labels.\"\"\"\n    \n    images_list = []\n    img_names = os.listdir(file_dir + \"test/\")\n    for img_name in img_names:\n        img_bgr = cv2.imread(file_dir + 'test/' + img_name)\n        img_equalized = equalize(img_bgr)\n        img_seedling = extract_seedling(img_equalized)\n        # cv2.imwrite(cls_folder + '/' + img_name, img_seedling)\n\n        images_list.append(img_seedling)\n    return images_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_list_test = preprocessing_test_imgs(data_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(imgs_list_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(imgs_list_test[0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# feature_sift_list_test = sift_feature(imgs_list_test)  # 不需要\n# bow_extractor_test = bow_init(feature_sift_list_test)  # 不需要\n\nfeature_bow_test = bow_feature(bow_extractor, imgs_list_test)  # shape = (794, 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(feature_bow_test), len(feature_bow_test))\nfeature_bow_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_bow_test[np.isnan(feature_bow_test)]    # Test for nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Normalize\nfeature_bow_normal_test = normalize(feature_bow_test)\n\n## Dimensionality Reduction\nfeature_bow_pca_test = dimensionalityReduction(feature_bow_normal_test, 100)\nfeature_bow_pca_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimgs_list_test = resize_imgs(imgs_list_test)     # Resize images\n\nfeature_hog_test = hog_feature(imgs_list_test)   # (794, 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_hog_test[np.isnan(feature_hog_test)]   # Test for nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Normalize\nfeature_hog_normal_test = normalize(feature_hog_test)\n\n## Dimensionality Reduction\nfeature_hog_pca_test = dimensionalityReduction(feature_hog_normal_test, 100)\nfeature_hog_pca_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 获取 LBP 特征\nfeature_lbp_test = lbp_feature(imgs_list_test)     # (794, 3, 128, 128)\ntype(feature_lbp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Reshape into 2 Dimensions\nfeature_lbp_test = feature_lbp_test.reshape(feature_lbp_test.shape[0], -1)\nfeature_lbp_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_lbp_test[np.isnan(feature_lbp_test)]   # Test for nan\n\n# feature_lbp_test[np.logical_not(np.isnan(feature_lbp_test))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Fill nan with 0\nfeature_lbp_test = fill_missing(feature_lbp_test)\nfeature_lbp_test[np.isnan(feature_lbp_test)]        # Test for nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Normalize\nfeature_lbp_normal_test = normalize(feature_lbp_test)\n\n## Dimensionality Reduction\nfeature_lbp_pca_test = dimensionalityReduction(feature_lbp_normal_test, 100)\nfeature_lbp_pca_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将 SIFT+BOW, HOG, LBP 三种特征矩阵拼合到一起\nfeatures_list_test = [feature_bow_pca_test, feature_hog_pca_test, feature_lbp_pca_test]\n\n\nfeatures_test = [[] for i in range(1104)]\n\nfor feature in features_list_test:\n    features_test = np.hstack((features_test, feature))\n    \nprint(features_test.shape)\n\n# np.save(feature_dir + 'features_test', features_test, allow_pickle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_test = model_stack.predict(features_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predict_test.shape)\n\npredict_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_names = os.listdir(data_dir + \"test/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.imread(data_dir + \"test/\" +os.listdir(data_dir + \"test/\")[0]))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_dict.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_to_class_dict = dict(zip(classes_dict.values(), classes_dict.keys()))\n# num_to_class_dict ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_class = []\nfor pred in predict_test:\n    predict_class.append(num_to_class_dict[pred])\n# predict_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['file'] = img_names\ndf_submission['species'] = predict_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}